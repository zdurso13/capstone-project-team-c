---
title: "EDA"
output: html_document
date: "2025-11-14"
---

libraies
```{r}
library(dplyr)
library(lubridate)
library(readr)
```


Importing data
```{r}
weather = read.csv("data/weather-data.csv")
airquality = read.csv("data/air-quality-data.csv")
boston = read.csv("data/boston-marathon-data.csv")
chicago = read.csv("data/chicago-marathon-data.csv")
nyc = read.csv("data/nyc-marathon-data.csv")
berlin = read.csv("data/berlin-marathon-data.csv")
```

Taking a look at the datasets
```{r}
str(boston)
str(berlin)
str(nyc)
str(chicago)
str(weather)
str(airquality)
```

Standardize all the marathon datasets
```{r}
boston_clean <- boston %>%
  transmute(
    year = year,
    marathon = "Boston",
    gender = gender,
    chip_time = official_time
  )

berlin_clean <- berlin %>%
  transmute(
    year = YEAR,
    marathon = "Berlin",
    gender = GENDER,
    chip_time = TIME
  )

nyc_clean <- nyc %>%
  transmute(
    year = Year,
    marathon = "NYC",
    gender = Gender,
    chip_time = Finish.Time
  )

chicago_clean <- chicago %>%
  transmute(
    year = Year,
    marathon = "Chicago",
    gender = Gender,
    chip_time = Finish.Time
  )
```

Standardize weather data
```{r}
weather_clean <- weather %>%
  transmute(
    year = Year,
    marathon = Marathon,
    high_temp = High.Temp,
    low_temp = Low.Temp,
    avg_temp = Day.Average.Temp,
    precipitation = Precipitation,
    dew_point = Average.Dew.Point,
    wind_speed = Max.Wind.Speed,
    visibility = Visibility,
    sea_level_pressure = Sea.Level.Pressure
  )
```

Standardize airquality data
```{r}
airquality_clean <- airquality %>%
  transmute(
    year = Year,
    marathon = Marathon,
    aqi = Overall.AQI.Value,
    main_pollutant = Main.Pollutant,
    co = as.numeric(CO),
    ozone = as.numeric(Ozone),
    pm10 = suppressWarnings(as.numeric(PM10)),
    pm25 = as.numeric(PM2.5),
    no2 = as.numeric(NO2)
  )
```

Combine the marathon datasets
```{r}
# using bind_rows so we can row-wise combine and have data for each runner
marathons_all <- bind_rows(
  boston_clean,
  berlin_clean,
  nyc_clean,
  chicago_clean
)
str(marathons_all)
```

Select only years we need (1996 to 2025)
```{r}
marathons_all <- marathons_all %>%
  filter(year >= 1996 & year <= 2025)

str(marathons_all)
```

Chip-Time Cleaning Function (pulled from chatgbt): need chip_seconds to find the average finishing times
```{r}
clean_chip_time <- function(x) {
  
  # Convert numeric Excel-style times to character HH:MM:SS
  x_numeric <- suppressWarnings(as.numeric(x))
  is_fraction <- !is.na(x_numeric) & x_numeric < 1 & x_numeric > 0
  
  x[is_fraction] <- format(
    as.POSIXct("1970-01-01", tz = "UTC") + x_numeric[is_fraction] * 86400,
    "%H:%M:%S"
  )
  
  # Everything else treat as text and clean
  x <- as.character(x)
  x <- trimws(x)
  
  # Replace known invalid strings with NA
  invalid <- c("", "NA", "N/A", "—", "-", "DNF", "DNS", "DQ", "no time", "No Time", "NO TIME")
  x[x %in% invalid] <- NA
  
  # Pad missing zeros (H:MM:SS → HH:MM:SS, etc.)
  x <- gsub("^([0-9]):", "0\\1:", x)
  x <- gsub(":([0-9]):", ":0\\1:", x)
  x <- gsub(":([0-9])$", ":0\\1", x)
  
  return(x)
}

```

Clean chip_time
```{r}
marathons_all <- marathons_all %>%
  mutate(chip_time_clean = clean_chip_time(chip_time))
```

Convert the cleaned chip_time values to H:M:S and get chip_seconds
```{r}
marathons_all <- marathons_all %>%
  mutate(
    chip_seconds = suppressWarnings(period_to_seconds(hms(chip_time_clean)))
  )
```

```{r}
head(marathons_all)
```

Need to see what we want to do with these missing values and where they are coming from
```{r}
marathons_all %>% 
  summarize(missing_finish_times = sum(is.na(chip_seconds)))

marathons_all %>% 
  filter(is.na(chip_seconds))
```

Remove missing finish times. This is safe because we only use average finishing times in our model, so individual missing times don not matter. Also there are only 3 total. 
```{r}
marathons_all <- marathons_all %>%
  filter(!is.na(chip_seconds))
```

Labeling Gender as 'male', 'female', or 'unknown', nonbinary falls under female

```{r}
unique(marathons_all$gender)
```

```{r}
marathons_all <- marathons_all %>%
  mutate(
    gender = tolower(gender),
    gender = case_when(
      gender %in% c("male", "m") ~ "male",
      gender %in% c("female", "f", "w", "x", "nonbinary", "nb") ~ "female",
      TRUE ~ "unknown"
    )
  )

table(marathons_all$gender)
```

Removing unknowns since we have only 29 unknowns, and they will not help the model and most likely add noise:
```{r}
marathons_all <- marathons_all %>% 
  filter(gender != "unknown")

table(marathons_all$gender)
```


Next we need to compute average finishing times, group by: year, marathon, gender, performance group: 

Adding performance subgroups based off quintile cutoffs:

Elite = 0–20th percentile

Competitive = 20–40th percentile

Average = 40–60th percentile

Recreational = 60–80th percentile

Slow = 80–100th percentile

```{r}
# Compute quintile cutoffs for each (marathon by year by gender)
quintile_groups <- marathons_all %>%
  filter(!is.na(chip_seconds),
         gender %in% c("male", "female")) %>% 
  group_by(marathon, year, gender) %>% 
  mutate(
    qtile = ntile(chip_seconds, 5),   # divides distribution into 5 equal groups
    subgroup = case_when(
      qtile == 1 ~ "elite",          # fastest 20%
      qtile == 2 ~ "competitive",
      qtile == 3 ~ "average",
      qtile == 4 ~ "recreational",
      qtile == 5 ~ "slow",           # slowest 20%
      TRUE ~ NA_character_
    )
  ) %>%
  ungroup()
```


```{r}
# order subgroubs from fastest to slowest
quintile_groups <- quintile_groups %>%
  mutate(
    subgroup = factor(subgroup,
                      levels = c("elite", "competitive", "average", "recreational", "slow"))
  )


# compute average finishing time per subgroup, adding number in each group to see if weighing needs to happen
avg_times <- quintile_groups %>%
  group_by(marathon, year, gender, subgroup) %>%
  summarize(
    avg_chip_seconds = mean(chip_seconds, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )

avg_times
```

Left join weather_clean and airquailty_clean onto the cleaned marathon datasets
```{r}
final_data <- avg_times %>%
  left_join(weather_clean, by = c("year", "marathon")) %>%
  left_join(airquality_clean, by = c("year", "marathon"))

# move n (number of individuals representing each group) to the first column for neatness
final_data <- final_data %>% 
  select(n, everything())

final_data
```

```{r}
# Table 1: Continuous Variable Summary
# Select the continuous variables
continuous_summary <- final_data %>%
  select(avg_chip_seconds, high_temp, low_temp, avg_temp, precipitation,
         dew_point, wind_speed, visibility, sea_level_pressure, aqi, pm10, pm25, no2, ozone, co) %>%
  summarise_all(list(
    mean = ~mean(., na.rm = TRUE),
    median = ~median(., na.rm = TRUE),
    sd = ~sd(., na.rm = TRUE),
    min = ~min(., na.rm = TRUE),
    max = ~max(., na.rm = TRUE)
  ))
continuous_summary
```

```{r}
# Table 2: Continuous variables summarized by subgroup and gender
# Select continuous variables
continuous_summary_grouped <- final_data %>%
  group_by(gender, subgroup) %>% # group by gender and subgroup
  summarise(
    avg_chip_seconds_mean = mean(avg_chip_seconds, na.rm = TRUE),
    avg_chip_seconds_sd = sd(avg_chip_seconds, na.rm = TRUE),
    high_temp_mean = mean(high_temp, na.rm = TRUE),
    high_temp_sd = sd(high_temp, na.rm = TRUE),
    low_temp_mean = mean(low_temp, na.rm = TRUE),
    low_temp_sd = sd(low_temp, na.rm = TRUE),
    avg_temp_mean = mean(avg_temp, na.rm = TRUE),
    avg_temp_sd = sd(avg_temp, na.rm = TRUE),
    precipitation_mean = mean(precipitation, na.rm = TRUE),
    precipitation_sd = sd(precipitation, na.rm = TRUE),
    dew_point_mean = mean(dew_point, na.rm = TRUE),
    dew_point_sd = sd(dew_point, na.rm = TRUE),
    wind_speed_mean = mean(wind_speed, na.rm = TRUE),
    wind_speed_sd = sd(wind_speed, na.rm = TRUE),
    visibility_mean = mean(visibility, na.rm = TRUE),
    visibility_sd = sd(visibility, na.rm = TRUE),
    sea_level_pressure_mean = mean(sea_level_pressure, na.rm = TRUE),
    sea_level_pressure_sd = sd(sea_level_pressure, na.rm = TRUE),
    aqi_mean = mean(aqi, na.rm = TRUE),
    aqi_sd = sd(aqi, na.rm = TRUE),
    pm10_mean = mean(pm10, na.rm = TRUE),
    pm10_sd = sd(pm10, na.rm = TRUE),
    pm25_mean = mean(pm25, na.rm = TRUE),
    pm25_sd = sd(pm25, na.rm = TRUE),
    no2_mean = mean(no2, na.rm = TRUE),
    no2_sd = sd(no2, na.rm = TRUE),
    ozone_mean = mean(ozone, na.rm = TRUE),
    ozone_sd = sd(ozone, na.rm = TRUE),
    co_mean = mean(co, na.rm = TRUE),
    co_sd = sd(co, na.rm = TRUE)
  ) %>%
  arrange(gender, subgroup)
continuous_summary_grouped
```


```{r}
# Figure 1: Distribution of Average Finishing Times
library(ggplot2) # load plotting library
ggplot(final_data, aes(x = avg_chip_seconds / 3600)) + # convert from seconds to hours
  geom_histogram(bins = 20, fill = "steelblue", color = "black") + # create a histogram
  labs(title = "Distribution of Average Finishing Times", # generate labels
    x = "Average Finishing Time (hours)",
    y = "Frequency"
  )
```

```{r}
# Figure 2: Overview of the Effect of Avg Temperature on Finishing Time by Marathon
ggplot(final_data, aes(x = avg_temp, y = avg_chip_seconds / 3600, color = marathon)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  facet_wrap(~ marathon, scales = "free_x") + # each marathon has own x-axis scale
  labs(title = "Overview of the Effect of Average Temperature on Finishing Time by Marathon",
    x = "Average Temperature (°F)",
    y = "Finishing Time (hours)"
  )
```

```{r}
# Figure 3: Overview of the Relationship Between Air Quality and Finishing Time by Marathon
ggplot(final_data, aes(x = aqi, y = avg_chip_seconds / 3600, color = marathon)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = FALSE, color = "black") +
  facet_wrap(~ marathon, scales = "free_x") + 
  labs(title = "Overview of the Relationship Between Air Quality and Finishing Time by Marathon",
    x = "Air Quality Index (AQI)",
    y = "Average Finishing Time (hours)"
  ) +
  theme(legend.position = "none")
```

```{r}
# select only the numeric variables
numeric_vars <- final_data %>%
  select(avg_chip_seconds, avg_temp, precipitation, dew_point,
         wind_speed, visibility, sea_level_pressure,
         aqi, pm10, pm25, no2, ozone, co)

# create correlation matrix
cor_matrix <- cor(numeric_vars, use = "complete.obs")

# round the correlations
round(cor_matrix, 2)
```

Export final data to csv
```{r}
#write_csv(final_data, "merged_marathon_data.csv")
```

