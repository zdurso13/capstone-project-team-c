---
title: "EDA"
output: html_document
date: "2025-11-14"
---

libraies
```{r}
library(dplyr)
library(lubridate)
library(readr)
```

Importing data
```{r}
weather = read.csv("data/weather-data.csv")
airquality = read.csv("data/air-quality-data.csv")
boston = read.csv("data/boston-marathon-data.csv")
chicago = read.csv("data/chicago-marathon-data.csv")
nyc = read.csv("data/nyc-marathon-data.csv")
berlin = read.csv("data/berlin-marathon-data.csv")
```

Taking a look at the datasets
```{r}
str(boston)
str(berlin)
str(nyc)
str(chicago)
str(weather)
str(airquality)
```

Standardize all the marathon datasets
```{r}
boston_clean <- boston %>%
  transmute(
    year = year,
    marathon = "Boston",
    gender = gender,
    chip_time = official_time
  )

berlin_clean <- berlin %>%
  transmute(
    year = YEAR,
    marathon = "Berlin",
    gender = GENDER,
    chip_time = TIME
  )

nyc_clean <- nyc %>%
  transmute(
    year = Year,
    marathon = "NYC",
    gender = Gender,
    chip_time = Finish.Time
  )

chicago_clean <- chicago %>%
  transmute(
    year = Year,
    marathon = "Chicago",
    gender = Gender,
    chip_time = Finish.Time
  )
```

Standardize weather data
```{r}
weather_clean <- weather %>%
  transmute(
    year = Year,
    marathon = Marathon,
    high_temp = High.Temp,
    low_temp = Low.Temp,
    avg_temp = Day.Average.Temp,
    precipitation = Precipitation,
    dew_point = Average.Dew.Point,
    wind_speed = Max.Wind.Speed,
    visibility = Visibility,
    sea_level_pressure = Sea.Level.Pressure
  )
```

Standardize airquality data
```{r}
airquality_clean <- airquality %>%
  transmute(
    year = Year,
    marathon = Marathon,
    aqi = Overall.AQI.Value,
    main_pollutant = Main.Pollutant,
    co = as.numeric(CO),
    ozone = as.numeric(Ozone),
    pm10 = suppressWarnings(as.numeric(PM10)),
    pm25 = as.numeric(PM2.5),
    no2 = as.numeric(NO2)
  )
```

Combine the marathon datasets
```{r}
# using bind_rows so we can row-wise combine and have data for each runner
marathons_all <- bind_rows(
  boston_clean,
  berlin_clean,
  nyc_clean,
  chicago_clean
)
str(marathons_all)
```

Select only years we need (1996 to 2019)
```{r}
marathons_all <- marathons_all %>%
  filter(year >= 1996 & year <= 2019)

str(marathons_all)
```

Chip-Time Cleaning Function (pulled from chatgbt): need chip_seconds to find the average finishing times
```{r}
clean_chip_time <- function(x) {
  
  # Convert numeric Excel-style times to character HH:MM:SS
  x_numeric <- suppressWarnings(as.numeric(x))
  is_fraction <- !is.na(x_numeric) & x_numeric < 1 & x_numeric > 0
  
  x[is_fraction] <- format(
    as.POSIXct("1970-01-01", tz = "UTC") + x_numeric[is_fraction] * 86400,
    "%H:%M:%S"
  )
  
  # Everything else treat as text and clean
  x <- as.character(x)
  x <- trimws(x)
  
  # Replace known invalid strings with NA
  invalid <- c("", "NA", "N/A", "—", "-", "DNF", "DNS", "DQ", "no time", "No Time", "NO TIME")
  x[x %in% invalid] <- NA
  
  # Pad missing zeros (H:MM:SS → HH:MM:SS, etc.)
  x <- gsub("^([0-9]):", "0\\1:", x)
  x <- gsub(":([0-9]):", ":0\\1:", x)
  x <- gsub(":([0-9])$", ":0\\1", x)
  
  return(x)
}

```

Clean chip_time
```{r}
marathons_all <- marathons_all %>%
  mutate(chip_time_clean = clean_chip_time(chip_time))
```

Convert the cleaned chip_time values to H:M:S and get chip_seconds
```{r}
marathons_all <- marathons_all %>%
  mutate(
    chip_seconds = suppressWarnings(period_to_seconds(hms(chip_time_clean)))
  )
```

```{r}
head(marathons_all)
```

Need to see what we want to do with these missing values and where they are coming from
```{r}
marathons_all %>% 
  summarize(missing_finish_times = sum(is.na(chip_seconds)))

marathons_all %>% 
  filter(is.na(chip_seconds))
```

Remove missing finish times. This is safe because we only use average finishing times in our model, so individual missing times don not matter. Also there are only 3 total. 
```{r}
marathons_all <- marathons_all %>%
  filter(!is.na(chip_seconds))
```

Labeling Gender as 'male', 'female', or 'unknown', nonbinary falls under female

```{r}
unique(marathons_all$gender)
```

```{r}
marathons_all <- marathons_all %>%
  mutate(
    gender = tolower(gender),
    gender = case_when(
      gender %in% c("male", "m") ~ "male",
      gender %in% c("female", "f", "w", "x", "nonbinary", "nb") ~ "female",
      TRUE ~ "unknown"
    )
  )

table(marathons_all$gender)
```

Removing unknowns since we have only 29 unknowns, and they will not help the model and most likely add noise:
```{r}
marathons_all <- marathons_all %>% 
  filter(gender != "unknown")

table(marathons_all$gender)
```


Next we need to compute average finishing times, group by: year, marathon, gender, performance group: 

Adding performance subgroups based off quintile cutoffs:

Elite = 0–20th percentile

Competitive = 20–40th percentile

Average = 40–60th percentile

Recreational = 60–80th percentile

Slow = 80–100th percentile

```{r}
# Compute quintile cutoffs for each (marathon by year by gender)
quintile_groups <- marathons_all %>%
  filter(!is.na(chip_seconds),
         gender %in% c("male", "female")) %>% 
  group_by(marathon, year, gender) %>% 
  mutate(
    qtile = ntile(chip_seconds, 5),   # divides distribution into 5 equal groups
    subgroup = case_when(
      qtile == 1 ~ "elite",          # fastest 20%
      qtile == 2 ~ "competitive",
      qtile == 3 ~ "average",
      qtile == 4 ~ "recreational",
      qtile == 5 ~ "slow",           # slowest 20%
      TRUE ~ NA_character_
    )
  ) %>%
  ungroup()
```


```{r}
# order subgroubs from fastest to slowest
quintile_groups <- quintile_groups %>%
  mutate(
    subgroup = factor(subgroup,
                      levels = c("elite", "competitive", "average", "recreational", "slow"))
  )


# compute average finishing time per subgroup, adding number in each group to see if weighing needs to happen
avg_times <- quintile_groups %>%
  group_by(marathon, year, gender, subgroup) %>%
  summarize(
    avg_chip_seconds = mean(chip_seconds, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )

avg_times
```

Left join weather_clean and airquailty_clean onto the cleaned marathon datasets
```{r}
final_data <- avg_times %>%
  left_join(weather_clean, by = c("year", "marathon")) %>%
  left_join(airquality_clean, by = c("year", "marathon"))

# move n (number of indivuduals represting each group) to the first column for neatness
final_data <- final_data %>% 
  select(n, everything())

final_data
```

Export final data to csv
```{r}
#write_csv(final_data, "merged_marathon_data.csv")
```

